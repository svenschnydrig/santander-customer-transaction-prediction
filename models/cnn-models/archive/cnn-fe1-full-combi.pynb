{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary + Sum Full - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from math import ceil\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-sum/train_fe1_sum.csv\")\n",
    "one = train_data\n",
    "train_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-binary/train_fe1_binary.csv\")\n",
    "two = train_data.iloc[:, 202:]\n",
    "train_data = pd.concat([one, two], axis=1)\n",
    "y = train_data[\"target\"]\n",
    "X = train_data.drop([\"ID_code\", \"target\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "ds = TensorDataset(X_tensor, y_tensor)\n",
    "train_ds, val_ds = random_split(ds, [int(0.9*len(ds)), ceil(0.1*len(ds))])\n",
    "#for final training we use the whole dataset\n",
    "train_ds = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "test_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-sum/test_fe1_sum.csv\")\n",
    "one = test_data\n",
    "test_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-binary/test_fe1_binary.csv\")\n",
    "two = test_data.iloc[:, 201:]\n",
    "test_data = pd.concat([one, two], axis=1)\n",
    "test_ids = test_data[\"ID_code\"]\n",
    "X = test_data.drop([\"ID_code\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "test_ds = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary + Sum Full - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.5320685269099292\n",
      "VALIDATION ROC: 0.9071436795315675\n",
      "VALIDATION ROC: 0.9153927865544929\n",
      "VALIDATION ROC: 0.9200943416915439\n",
      "VALIDATION ROC: 0.923773475771058\n",
      "VALIDATION ROC: 0.9254571110581129\n",
      "VALIDATION ROC: 0.9277820998873326\n",
      "VALIDATION ROC: 0.9286297907568991\n",
      "VALIDATION ROC: 0.9293250655854995\n",
      "VALIDATION ROC: 0.9296526641282268\n",
      "VALIDATION ROC: 0.9304649511638172\n",
      "VALIDATION ROC: 0.9316206677248068\n",
      "VALIDATION ROC: 0.931694737534643\n",
      "VALIDATION ROC: 0.9324571192819999\n",
      "VALIDATION ROC: 0.9319783519878507\n",
      "VALIDATION ROC: 0.9325723085273486\n",
      "VALIDATION ROC: 0.9328613370395651\n",
      "VALIDATION ROC: 0.9330181665666092\n",
      "VALIDATION ROC: 0.933687015304654\n",
      "VALIDATION ROC: 0.9338701749769046\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n",
      "torch.Size([1000, 1200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(6, hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size//6*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        og_features = x[:, :200].unsqueeze(2) # (N, 200, 1)\n",
    "        vc = x[:, 200:400].unsqueeze(2) # (N, 200, 1)\n",
    "        sum = x[:, 400:600].unsqueeze(2) # (N, 200, 1)\n",
    "        sum2 = x[:, 600:800].unsqueeze(2) # (N, 200, 1)\n",
    "        sum3 = x[:, 800:1000].unsqueeze(2) # (N, 200, 1)\n",
    "        binary = x[:, 1000:].unsqueeze(2) # (N, 200, 1)\n",
    "        x = torch.cat([og_features, vc, sum, sum2, sum3, binary], dim = 2) # (N, 200, 2)\n",
    "        x = F.relu(self.fc1(x)).reshape(N, -1) # (N, 200*hidden_dim)\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n",
    "\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "model = NN(input_size=1200, hidden_dim=200).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.BCELoss()\n",
    "train_loader = DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000)\n",
    "\n",
    "def get_predictions(loader, model, device):\n",
    "    model.eval()\n",
    "    saved_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            saved_preds += scores.tolist()\n",
    "            true_labels += y.tolist()\n",
    "\n",
    "    model.train()\n",
    "    return saved_preds, true_labels\n",
    "\n",
    "for epoch in range(20):\n",
    "    probabilities, true = get_predictions(val_loader, model, device=DEVICE)\n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, probabilities)}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def get_submission(model, loader, test_ids, device):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            print(x.shape)\n",
    "            x = x.to(device)\n",
    "            score = model(x)\n",
    "            prediction = score.float()\n",
    "            all_preds += prediction.tolist()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"ID_code\" : test_ids.values,\n",
    "        \"target\" : np.array(all_preds)\n",
    "    })\n",
    "\n",
    "    df.to_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/submission/various_submissions/fe1_sum_binary_full.csv\", index=False)\n",
    "\n",
    "get_submission(model, test_loader, test_ids, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources\n",
    "- https://www.youtube.com/watch?v=MOnk75_8b9M&t=2995s\n",
    "- https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
    "- https://www.amazon.de/Sebastian-Raschka/dp/1801819319/ref=sr_1_1_sspa?crid=1LIHNO6T7C2AI&keywords=pylampe&qid=1671791736&sprefix=pytorch%2Caps%2C99&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1\n",
    "- https://medium.com/analytics-vidhya/santander-customer-transaction-prediction-an-end-to-end-machine-learning-project-2cb763172f8a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dce8878ebb52da75faff629455dee1fd1c94f17ecb542480b5d416cf2a25925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
