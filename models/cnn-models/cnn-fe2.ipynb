{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from math import ceil\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe2-binary/train_fe2_binary.csv\")\n",
    "y = train_data[\"target\"]\n",
    "X = train_data.drop([\"ID_code\", \"target\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "ds = TensorDataset(X_tensor, y_tensor)\n",
    "train_ds, val_ds = random_split(ds, [int(0.9*len(ds)), ceil(0.1*len(ds))])\n",
    "#for final training we use the whole dataset\n",
    "train_ds = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "test_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe2-binary/test_fe2_binary.csv\")\n",
    "test_ids = test_data[\"ID_code\"]\n",
    "X = test_data.drop([\"ID_code\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "test_ds = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.5284195592292358\n",
      "VALIDATION ROC: 0.9146103340682112\n",
      "VALIDATION ROC: 0.9195261916252279\n",
      "VALIDATION ROC: 0.9218650588646315\n",
      "VALIDATION ROC: 0.9221349864894455\n",
      "VALIDATION ROC: 0.9226086389595776\n",
      "VALIDATION ROC: 0.9243971061264146\n",
      "VALIDATION ROC: 0.9249448699932465\n",
      "VALIDATION ROC: 0.9243810054290247\n",
      "VALIDATION ROC: 0.9247614410974553\n",
      "VALIDATION ROC: 0.9256089670679793\n",
      "VALIDATION ROC: 0.9257375317035629\n",
      "VALIDATION ROC: 0.9258765561231902\n",
      "VALIDATION ROC: 0.9264922093742627\n",
      "VALIDATION ROC: 0.9253587259472801\n",
      "VALIDATION ROC: 0.9259041370713595\n",
      "VALIDATION ROC: 0.9261218649879989\n",
      "VALIDATION ROC: 0.9259249716005526\n",
      "VALIDATION ROC: 0.9259120598617127\n",
      "VALIDATION ROC: 0.9260746542283111\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n",
      "torch.Size([1000, 370])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size//2*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        og_features = x[:, :185].unsqueeze(2) # (N, 200, 1)\n",
    "        new_features = x[:, 185:].unsqueeze(2) # (N, 200, 1)\n",
    "        x = torch.cat([og_features, new_features], dim = 2) # (N, 200, 2)\n",
    "        x = F.relu(self.fc1(x)).reshape(N, -1) # (N, 200*hidden_dim)\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n",
    "\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "model = NN(input_size=370, hidden_dim=200).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.BCELoss()\n",
    "train_loader = DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000)\n",
    "\n",
    "def get_predictions(loader, model, device):\n",
    "    model.eval()\n",
    "    saved_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            saved_preds += scores.tolist()\n",
    "            true_labels += y.tolist()\n",
    "\n",
    "    model.train()\n",
    "    return saved_preds, true_labels\n",
    "\n",
    "for epoch in range(20):\n",
    "    probabilities, true = get_predictions(val_loader, model, device=DEVICE)\n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, probabilities)}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def get_submission(model, loader, test_ids, device):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            print(x.shape)\n",
    "            x = x.to(device)\n",
    "            score = model(x)\n",
    "            prediction = score.float()\n",
    "            all_preds += prediction.tolist()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"ID_code\" : test_ids.values,\n",
    "        \"target\" : np.array(all_preds)\n",
    "    })\n",
    "\n",
    "    df.to_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/submission/various_submissions/fe2_binary.csv\", index=False)\n",
    "\n",
    "get_submission(model, test_loader, test_ids, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from math import ceil\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe2-sum/train_fe2_sum.csv\")\n",
    "y = train_data[\"target\"]\n",
    "X = train_data.drop([\"ID_code\", \"target\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "ds = TensorDataset(X_tensor, y_tensor)\n",
    "train_ds, val_ds = random_split(ds, [int(0.9*len(ds)), ceil(0.1*len(ds))])\n",
    "#for final training we use the whole dataset\n",
    "train_ds = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "test_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe2-sum/test_fe2_sum.csv\")\n",
    "test_ids = test_data[\"ID_code\"]\n",
    "X = test_data.drop([\"ID_code\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "test_ds = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.47650633057504393\n",
      "VALIDATION ROC: 0.9074651522098831\n",
      "VALIDATION ROC: 0.9153364195319942\n",
      "VALIDATION ROC: 0.9201236751721716\n",
      "VALIDATION ROC: 0.9236999221710588\n",
      "VALIDATION ROC: 0.9253961925549404\n",
      "VALIDATION ROC: 0.9271585537175396\n",
      "VALIDATION ROC: 0.9285721948982817\n",
      "VALIDATION ROC: 0.9280809361568305\n",
      "VALIDATION ROC: 0.9291376183595754\n",
      "VALIDATION ROC: 0.9310836444895448\n",
      "VALIDATION ROC: 0.9298832818966888\n",
      "VALIDATION ROC: 0.9314374674222665\n",
      "VALIDATION ROC: 0.9316476374740464\n",
      "VALIDATION ROC: 0.9325056484576875\n",
      "VALIDATION ROC: 0.9324301632977289\n",
      "VALIDATION ROC: 0.9332097456403194\n",
      "VALIDATION ROC: 0.9334438761783691\n",
      "VALIDATION ROC: 0.9329319305417688\n",
      "VALIDATION ROC: 0.9332427979069704\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n",
      "torch.Size([1000, 925])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(5, hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size//5*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        og_features = x[:, :185].unsqueeze(2) # (N, 200, 1)\n",
    "        vc = x[:, 185:370].unsqueeze(2) # (N, 200, 1)\n",
    "        sum = x[:, 370:555].unsqueeze(2) # (N, 200, 1)\n",
    "        sum2 = x[:, 555:740].unsqueeze(2) # (N, 200, 1)\n",
    "        sum3 = x[:, 740:].unsqueeze(2) # (N, 200, 1)\n",
    "        x = torch.cat([og_features, vc, sum, sum2, sum3], dim = 2) # (N, 200, 2)\n",
    "        x = F.relu(self.fc1(x)).reshape(N, -1) # (N, 200*hidden_dim)\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n",
    "\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "model = NN(input_size=925, hidden_dim=200).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.BCELoss()\n",
    "train_loader = DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000)\n",
    "\n",
    "def get_predictions(loader, model, device):\n",
    "    model.eval()\n",
    "    saved_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            saved_preds += scores.tolist()\n",
    "            true_labels += y.tolist()\n",
    "\n",
    "    model.train()\n",
    "    return saved_preds, true_labels\n",
    "\n",
    "for epoch in range(20):\n",
    "    probabilities, true = get_predictions(val_loader, model, device=DEVICE)\n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, probabilities)}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def get_submission(model, loader, test_ids, device):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            print(x.shape)\n",
    "            x = x.to(device)\n",
    "            score = model(x)\n",
    "            prediction = score.float()\n",
    "            all_preds += prediction.tolist()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"ID_code\" : test_ids.values,\n",
    "        \"target\" : np.array(all_preds)\n",
    "    })\n",
    "\n",
    "    df.to_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/submission/various_submissions/fe2_sum.csv\", index=False)\n",
    "\n",
    "get_submission(model, test_loader, test_ids, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources\n",
    "- https://www.youtube.com/watch?v=MOnk75_8b9M&t=2995s\n",
    "- https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
    "- https://www.amazon.de/Sebastian-Raschka/dp/1801819319/ref=sr_1_1_sspa?crid=1LIHNO6T7C2AI&keywords=pylampe&qid=1671791736&sprefix=pytorch%2Caps%2C99&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1\n",
    "- https://medium.com/analytics-vidhya/santander-customer-transaction-prediction-an-end-to-end-machine-learning-project-2cb763172f8a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dce8878ebb52da75faff629455dee1fd1c94f17ecb542480b5d416cf2a25925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
