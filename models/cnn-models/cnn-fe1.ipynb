{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from math import ceil\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-binary/train_fe1_binary.csv\")\n",
    "y = train_data[\"target\"]\n",
    "X = train_data.drop([\"ID_code\", \"target\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "ds = TensorDataset(X_tensor, y_tensor)\n",
    "train_ds, val_ds = random_split(ds, [int(0.9*len(ds)), ceil(0.1*len(ds))])\n",
    "#for final training we use the whole dataset\n",
    "train_ds = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "test_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-binary/test_fe1_binary.csv\")\n",
    "test_ids = test_data[\"ID_code\"]\n",
    "X = test_data.drop([\"ID_code\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "test_ds = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.5720433929158676\n",
      "VALIDATION ROC: 0.9064744447372165\n",
      "VALIDATION ROC: 0.911923451660937\n",
      "VALIDATION ROC: 0.9148552854562378\n",
      "VALIDATION ROC: 0.9167999869273837\n",
      "VALIDATION ROC: 0.9185485583014857\n",
      "VALIDATION ROC: 0.9197756684566619\n",
      "VALIDATION ROC: 0.9201595676232146\n",
      "VALIDATION ROC: 0.9212593695594598\n",
      "VALIDATION ROC: 0.9215379388433048\n",
      "VALIDATION ROC: 0.9213789295297468\n",
      "VALIDATION ROC: 0.9233873736228646\n",
      "VALIDATION ROC: 0.9232724843894576\n",
      "VALIDATION ROC: 0.9225463005517052\n",
      "VALIDATION ROC: 0.9231271332365141\n",
      "VALIDATION ROC: 0.9243469445142332\n",
      "VALIDATION ROC: 0.9239077182224782\n",
      "VALIDATION ROC: 0.9241019418963055\n",
      "VALIDATION ROC: 0.9246208702958156\n",
      "VALIDATION ROC: 0.9241714446398528\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n",
      "torch.Size([1000, 400])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size//2*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        og_features = x[:, :200].unsqueeze(2) # (N, 200, 1)\n",
    "        new_features = x[:, 200:].unsqueeze(2) # (N, 200, 1)\n",
    "        x = torch.cat([og_features, new_features], dim = 2) # (N, 200, 2)\n",
    "        x = F.relu(self.fc1(x)).reshape(N, -1) # (N, 200*hidden_dim)\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n",
    "\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "model = NN(input_size=400, hidden_dim=200).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "train_loader = DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000)\n",
    "\n",
    "def get_predictions(loader, model, device):\n",
    "    model.eval()\n",
    "    saved_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            saved_preds += scores.tolist()\n",
    "            true_labels += y.tolist()\n",
    "\n",
    "    model.train()\n",
    "    return saved_preds, true_labels\n",
    "\n",
    "for epoch in range(20):\n",
    "    probabilities, true = get_predictions(val_loader, model, device=DEVICE)\n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, probabilities)}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def get_submission(model, loader, test_ids, device):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            print(x.shape)\n",
    "            x = x.to(device)\n",
    "            score = model(x)\n",
    "            prediction = score.float()\n",
    "            all_preds += prediction.tolist()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"ID_code\" : test_ids.values,\n",
    "        \"target\" : np.array(all_preds)\n",
    "    })\n",
    "\n",
    "    df.to_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/submission/various_submissions/fe1_binary.csv\", index=False)\n",
    "\n",
    "get_submission(model, test_loader, test_ids, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from math import ceil\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-sum/train_fe1_sum.csv\")\n",
    "y = train_data[\"target\"]\n",
    "X = train_data.drop([\"ID_code\", \"target\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "ds = TensorDataset(X_tensor, y_tensor)\n",
    "train_ds, val_ds = random_split(ds, [int(0.9*len(ds)), ceil(0.1*len(ds))])\n",
    "#for final training we use the whole dataset\n",
    "train_ds = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "test_data = pd.read_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/data/fe1-sum/test_fe1_sum.csv\")\n",
    "test_ids = test_data[\"ID_code\"]\n",
    "X = test_data.drop([\"ID_code\"], axis=1)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "test_ds = TensorDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.5043079079914253\n",
      "VALIDATION ROC: 0.9038657187952707\n",
      "VALIDATION ROC: 0.9123142262787911\n",
      "VALIDATION ROC: 0.9175648517055162\n",
      "VALIDATION ROC: 0.9196406456629936\n",
      "VALIDATION ROC: 0.9212910844650224\n",
      "VALIDATION ROC: 0.9229965351048455\n",
      "VALIDATION ROC: 0.9240308273788771\n",
      "VALIDATION ROC: 0.9253327463172817\n",
      "VALIDATION ROC: 0.9262446599123566\n",
      "VALIDATION ROC: 0.9272840001674479\n",
      "VALIDATION ROC: 0.9284252343385759\n",
      "VALIDATION ROC: 0.9286720276225524\n",
      "VALIDATION ROC: 0.9293919506009594\n",
      "VALIDATION ROC: 0.9297987174725602\n",
      "VALIDATION ROC: 0.9311986676453614\n",
      "VALIDATION ROC: 0.9307444051287599\n",
      "VALIDATION ROC: 0.9311391795591685\n",
      "VALIDATION ROC: 0.932142207817906\n",
      "VALIDATION ROC: 0.9317892256505824\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(5, hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size//5*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        og_features = x[:, :200].unsqueeze(2) # (N, 200, 1)\n",
    "        vc = x[:, 200:400].unsqueeze(2) # (N, 200, 1)\n",
    "        sum = x[:, 400:600].unsqueeze(2) # (N, 200, 1)\n",
    "        sum2 = x[:, 600:800].unsqueeze(2) # (N, 200, 1)\n",
    "        sum3 = x[:, 800:].unsqueeze(2) # (N, 200, 1)\n",
    "        x = torch.cat([og_features, vc, sum, sum2, sum3], dim = 2) # (N, 200, 2)\n",
    "        x = F.relu(self.fc1(x)).reshape(N, -1) # (N, 200*hidden_dim)\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n",
    "\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "model = NN(input_size=1000, hidden_dim=200).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "train_loader = DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000)\n",
    "\n",
    "def get_predictions(loader, model, device):\n",
    "    model.eval()\n",
    "    saved_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            saved_preds += scores.tolist()\n",
    "            true_labels += y.tolist()\n",
    "\n",
    "    model.train()\n",
    "    return saved_preds, true_labels\n",
    "\n",
    "for epoch in range(20):\n",
    "    probabilities, true = get_predictions(val_loader, model, device=DEVICE)\n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, probabilities)}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def get_submission(model, loader, test_ids, device):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            print(x.shape)\n",
    "            x = x.to(device)\n",
    "            score = model(x)\n",
    "            prediction = score.float()\n",
    "            all_preds += prediction.tolist()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"ID_code\" : test_ids.values,\n",
    "        \"target\" : np.array(all_preds)\n",
    "    })\n",
    "\n",
    "    df.to_csv(\"/Users/svenschnydrig/My Drive/Data Science Project - Team D/submission/various_submissions/fe1_sum.csv\", index=False)\n",
    "\n",
    "get_submission(model, test_loader, test_ids, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources\n",
    "- https://www.youtube.com/watch?v=MOnk75_8b9M&t=2995s\n",
    "- https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
    "- https://www.amazon.de/Sebastian-Raschka/dp/1801819319/ref=sr_1_1_sspa?crid=1LIHNO6T7C2AI&keywords=pylampe&qid=1671791736&sprefix=pytorch%2Caps%2C99&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1\n",
    "- https://medium.com/analytics-vidhya/santander-customer-transaction-prediction-an-end-to-end-machine-learning-project-2cb763172f8a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dce8878ebb52da75faff629455dee1fd1c94f17ecb542480b5d416cf2a25925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
