{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15419,"status":"ok","timestamp":1671754356530,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"},"user_tz":-60},"id":"mkRE647nj_iM","outputId":"7e2a2538-730e-4a6a-d113-7460e31344b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["## Importing libraries\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold\n","import lightgbm as lgb\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","SEED = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aT_wknkikKOg"},"outputs":[],"source":["## Importing data\n","\n","df_train = pd.read_csv(\"/content/drive/MyDrive/Data Science Project - Team D/data/fe1-sum/train_fe1_sum_lgbm.csv\")\n","df_test = pd.read_csv(\"/content/drive/MyDrive/Data Science Project - Team D/data/fe1-sum/test_fe1_sum_lgbm.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9dq23A0vkGxo"},"outputs":[],"source":["## Oversampling \n","\n","def oversampling(x, y, t=2):\n","    \n","    xs, xn = [], []\n","    \n","    for i in range(t // 2):\n","        mask = y == 0\n","        x1 = x[mask].copy()\n","        ids = np.arange(x1.shape[0])\n","        featnum = x1.shape[1] // 200 - 1\n","\n","        for c in range(200):\n","            np.random.shuffle(ids)\n","            x1[:, [c] + [200 + featnum * c + idc for idc in range(featnum)]] = x1[ids][:, [c] + [200 + featnum * c + idc for idc in range(featnum)]]\n","        xn.append(x1)\n","    \n","    for i in range(t):\n","        mask = y \u003e 0\n","        x1 = x[mask].copy()\n","        ids = np.arange(x1.shape[0])\n","        featnum = x1.shape[1] // 200 - 1\n","        \n","        for c in range(200):\n","            np.random.shuffle(ids)\n","            x1[:, [c] + [200 + featnum * c + idc for idc in range(1)]] = x1[ids][:, [c] + [200 + featnum * c + idc for idc in range(1)]]\n","        xs.append(x1)\n","\n","    xs = np.vstack(xs)\n","    xn = np.vstack(xn)\n","    ys = np.ones(xs.shape[0])\n","    yn = np.zeros(xn.shape[0])\n","    x = np.vstack([x, xs, xn])\n","    y = np.concatenate([y, ys, yn])\n","    \n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aIGjpIRWo0-B"},"outputs":[],"source":["gbdt_param1 = {\n","    # Core Parameters\n","    'learning_rate': 0.1,\n","    'num_leaves': 31,\n","    'max_depth': -1,\n","    'min_data_in_leaf': 20,\n","    'bagging_fraction': 1.0,\n","    'bagging_freq': 0,\n","    'feature_fraction': 1.0,\n","    'lambda_l1': 0,\n","    \n","    # Side Parameters\n","    'num_threads': 8,\n","    'seed': SEED,\n","    'tree_learner': 'serial',\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'bagging_seed': SEED,\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}\n","\n","gbdt_param2 = {\n","    # Core Parameters\n","    'learning_rate': 0.1,\n","    'num_leaves': 15,\n","    'max_depth': -1,\n","    'min_data_in_leaf': 80,\n","    'min_sum_hessian_in_leaf': 10,\n","    'bagging_fraction': 0.6,\n","    'bagging_freq': 5,\n","    'feature_fraction': 0.05,\n","    'lambda_l1': 1.,\n","    \n","    # Side Parameters\n","    'num_threads': 8,\n","    'seed': SEED,\n","    'tree_learner': 'serial',\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'bagging_seed': SEED,\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}\n","\n","gbdt_param3 = {\n","    # Core Parameters\n","    'learning_rate': 0.01,\n","    'num_leaves': 31,\n","    'max_depth': -1,\n","    'min_data_in_leaf': 20,  \n","    'bagging_fraction': 1.0,\n","    'bagging_freq': 0,\n","    'feature_fraction': 0.5,\n","    'lambda_l1': 0,\n","    \n","    # Side Parameters\n","    'num_threads': 8,\n","    'seed': SEED,\n","    'tree_learner': 'serial',\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'bagging_seed': SEED,\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}\n","\n","gbdt_param4 = {\n","    # Core Parameters\n","    'learning_rate': 0.01,\n","    'num_leaves': 15,\n","    'max_depth': -1,\n","    'min_data_in_leaf': 80,\n","    'min_sum_hessian_in_leaf': 10,  \n","    'bagging_fraction': 0.6,\n","    'bagging_freq': 5,\n","    'feature_fraction': 0.5,\n","    'lambda_l1': 1.,\n","    \n","    # Side Parameters\n","    'num_threads': 8,\n","    'seed': SEED,\n","    'tree_learner': 'serial',\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'bagging_seed': SEED,\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}\n","\n","gbdt_param5 = {\n","    # Core Parameters\n","    'learning_rate': 0.01,\n","    'num_leaves': 15,\n","    'max_depth': -1,\n","    'min_data_in_leaf': 50,\n","    'min_sum_hessian_in_leaf': 10,  \n","    'bagging_fraction': 0.6,\n","    'bagging_freq': 5,\n","    'feature_fraction': 0.05,\n","    'lambda_l1': 1.,\n","    \n","    # Side Parameters\n","    'num_threads': 8,\n","    'seed': SEED,\n","    'tree_learner': 'serial',\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'bagging_seed': SEED,\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Mlt5uEbB4gHf"},"outputs":[],"source":["predictors = df_train.columns.tolist()[2:]\n","X_test = df_test[predictors]\n","\n","n_splits = 5\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n","\n","predictions = df_test[['ID_code']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"17dOuWaqz2QC"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold 1 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.999981\tvalid_1's auc: 0.914691\n","[2000]\ttraining's auc: 1\tvalid_1's auc: 0.91344\n","[3000]\ttraining's auc: 1\tvalid_1's auc: 0.91307\n","[4000]\ttraining's auc: 1\tvalid_1's auc: 0.91287\n","[5000]\ttraining's auc: 1\tvalid_1's auc: 0.913039\n","Early stopping, best iteration is:\n","[648]\ttraining's auc: 0.999311\tvalid_1's auc: 0.915438\n","\n","Fold 2 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.999983\tvalid_1's auc: 0.914685\n","[2000]\ttraining's auc: 1\tvalid_1's auc: 0.913819\n","[3000]\ttraining's auc: 1\tvalid_1's auc: 0.913505\n","[4000]\ttraining's auc: 1\tvalid_1's auc: 0.912914\n","[5000]\ttraining's auc: 1\tvalid_1's auc: 0.913342\n","Early stopping, best iteration is:\n","[574]\ttraining's auc: 0.99876\tvalid_1's auc: 0.915266\n","\n","Fold 3 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.999984\tvalid_1's auc: 0.908913\n","[2000]\ttraining's auc: 1\tvalid_1's auc: 0.908671\n","[3000]\ttraining's auc: 1\tvalid_1's auc: 0.908374\n","[4000]\ttraining's auc: 1\tvalid_1's auc: 0.908283\n","[5000]\ttraining's auc: 1\tvalid_1's auc: 0.908561\n","Early stopping, best iteration is:\n","[524]\ttraining's auc: 0.998287\tvalid_1's auc: 0.909438\n","\n","Fold 4 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.999986\tvalid_1's auc: 0.911994\n","[2000]\ttraining's auc: 1\tvalid_1's auc: 0.911751\n","[3000]\ttraining's auc: 1\tvalid_1's auc: 0.911086\n","[4000]\ttraining's auc: 1\tvalid_1's auc: 0.911509\n","[5000]\ttraining's auc: 1\tvalid_1's auc: 0.911167\n","Early stopping, best iteration is:\n","[553]\ttraining's auc: 0.998621\tvalid_1's auc: 0.912837\n","\n","Fold 5 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.969246\tvalid_1's auc: 0.91312\n","[2000]\ttraining's auc: 0.830989\tvalid_1's auc: 0.619124\n","[3000]\ttraining's auc: 0.596167\tvalid_1's auc: 0.569613\n","[4000]\ttraining's auc: 0.596167\tvalid_1's auc: 0.569613\n","[5000]\ttraining's auc: 0.596167\tvalid_1's auc: 0.569613\n","Early stopping, best iteration is:\n","[519]\ttraining's auc: 0.998251\tvalid_1's auc: 0.918598\n"]}],"source":["# Parameter 1\n","\n","for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param1, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N\n","\n","predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n","\n","sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_parameter1.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wWQeClQwz4jj"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold 1 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.986425\tvalid_1's auc: 0.920051\n","[2000]\ttraining's auc: 0.99541\tvalid_1's auc: 0.918751\n","[3000]\ttraining's auc: 0.998887\tvalid_1's auc: 0.917847\n","[4000]\ttraining's auc: 0.999828\tvalid_1's auc: 0.916852\n","[5000]\ttraining's auc: 0.999984\tvalid_1's auc: 0.916367\n","[6000]\ttraining's auc: 1\tvalid_1's auc: 0.916164\n","Early stopping, best iteration is:\n","[1221]\ttraining's auc: 0.988936\tvalid_1's auc: 0.920277\n","\n","Fold 2 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.987129\tvalid_1's auc: 0.919626\n","[2000]\ttraining's auc: 0.995476\tvalid_1's auc: 0.91925\n","[3000]\ttraining's auc: 0.998942\tvalid_1's auc: 0.917566\n","[4000]\ttraining's auc: 0.999842\tvalid_1's auc: 0.916651\n","[5000]\ttraining's auc: 0.999986\tvalid_1's auc: 0.91621\n","[6000]\ttraining's auc: 0.999998\tvalid_1's auc: 0.915947\n","Early stopping, best iteration is:\n","[1474]\ttraining's auc: 0.991931\tvalid_1's auc: 0.920056\n","\n","Fold 3 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.986618\tvalid_1's auc: 0.91612\n","[2000]\ttraining's auc: 0.995535\tvalid_1's auc: 0.915754\n","[3000]\ttraining's auc: 0.998934\tvalid_1's auc: 0.914426\n","[4000]\ttraining's auc: 0.999838\tvalid_1's auc: 0.912878\n","[5000]\ttraining's auc: 0.999986\tvalid_1's auc: 0.912178\n","[6000]\ttraining's auc: 1\tvalid_1's auc: 0.911725\n","Early stopping, best iteration is:\n","[1355]\ttraining's auc: 0.990741\tvalid_1's auc: 0.917104\n","\n","Fold 4 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.986598\tvalid_1's auc: 0.920095\n","[2000]\ttraining's auc: 0.995231\tvalid_1's auc: 0.918802\n","[3000]\ttraining's auc: 0.998838\tvalid_1's auc: 0.917332\n","[4000]\ttraining's auc: 0.9998\tvalid_1's auc: 0.915956\n","[5000]\ttraining's auc: 0.999975\tvalid_1's auc: 0.915109\n","[6000]\ttraining's auc: 0.999998\tvalid_1's auc: 0.915184\n","Early stopping, best iteration is:\n","[1308]\ttraining's auc: 0.990157\tvalid_1's auc: 0.920241\n","\n","Fold 5 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.986638\tvalid_1's auc: 0.921367\n","[2000]\ttraining's auc: 0.995322\tvalid_1's auc: 0.920596\n","[3000]\ttraining's auc: 0.998772\tvalid_1's auc: 0.918813\n","[4000]\ttraining's auc: 0.999785\tvalid_1's auc: 0.917669\n","[5000]\ttraining's auc: 0.999973\tvalid_1's auc: 0.917162\n","[6000]\ttraining's auc: 0.999993\tvalid_1's auc: 0.917084\n","Early stopping, best iteration is:\n","[1045]\ttraining's auc: 0.987166\tvalid_1's auc: 0.921559\n"]}],"source":["# Parameter 2\n","\n","for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param2, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N\n","\n","predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n","\n","sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_parameter2.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kZN1md-Iz690"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold 1 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.970859\tvalid_1's auc: 0.880913\n","[2000]\ttraining's auc: 0.986642\tvalid_1's auc: 0.905425\n","[3000]\ttraining's auc: 0.991906\tvalid_1's auc: 0.914256\n","[4000]\ttraining's auc: 0.995076\tvalid_1's auc: 0.91812\n","[5000]\ttraining's auc: 0.997286\tvalid_1's auc: 0.919448\n","[6000]\ttraining's auc: 0.998563\tvalid_1's auc: 0.919828\n","[7000]\ttraining's auc: 0.999272\tvalid_1's auc: 0.919931\n","[8000]\ttraining's auc: 0.999653\tvalid_1's auc: 0.920045\n","[9000]\ttraining's auc: 0.999847\tvalid_1's auc: 0.919994\n","[10000]\ttraining's auc: 0.999939\tvalid_1's auc: 0.919918\n","[11000]\ttraining's auc: 0.999979\tvalid_1's auc: 0.919847\n","[12000]\ttraining's auc: 0.999994\tvalid_1's auc: 0.919812\n","[13000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.919858\n","Early stopping, best iteration is:\n","[8041]\ttraining's auc: 0.999666\tvalid_1's auc: 0.920062\n","\n","Fold 2 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.970759\tvalid_1's auc: 0.884761\n","[2000]\ttraining's auc: 0.986237\tvalid_1's auc: 0.906782\n","[3000]\ttraining's auc: 0.991686\tvalid_1's auc: 0.915396\n","[4000]\ttraining's auc: 0.994936\tvalid_1's auc: 0.918855\n","[5000]\ttraining's auc: 0.997191\tvalid_1's auc: 0.920041\n","[6000]\ttraining's auc: 0.998516\tvalid_1's auc: 0.92046\n","[7000]\ttraining's auc: 0.999256\tvalid_1's auc: 0.920658\n","[8000]\ttraining's auc: 0.999642\tvalid_1's auc: 0.920765\n","[9000]\ttraining's auc: 0.99984\tvalid_1's auc: 0.920759\n","[10000]\ttraining's auc: 0.999935\tvalid_1's auc: 0.920813\n","[11000]\ttraining's auc: 0.999977\tvalid_1's auc: 0.920807\n","[12000]\ttraining's auc: 0.999993\tvalid_1's auc: 0.920787\n","[13000]\ttraining's auc: 0.999998\tvalid_1's auc: 0.92066\n","[14000]\ttraining's auc: 1\tvalid_1's auc: 0.920687\n","[15000]\ttraining's auc: 1\tvalid_1's auc: 0.92069\n","[16000]\ttraining's auc: 1\tvalid_1's auc: 0.92063\n","Early stopping, best iteration is:\n","[11697]\ttraining's auc: 0.99999\tvalid_1's auc: 0.92083\n","\n","Fold 3 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.972227\tvalid_1's auc: 0.87696\n","[2000]\ttraining's auc: 0.987207\tvalid_1's auc: 0.900363\n","[3000]\ttraining's auc: 0.992262\tvalid_1's auc: 0.909449\n","[4000]\ttraining's auc: 0.995307\tvalid_1's auc: 0.913368\n","[5000]\ttraining's auc: 0.997408\tvalid_1's auc: 0.914886\n","[6000]\ttraining's auc: 0.998625\tvalid_1's auc: 0.915151\n","[7000]\ttraining's auc: 0.999309\tvalid_1's auc: 0.915343\n","[8000]\ttraining's auc: 0.999668\tvalid_1's auc: 0.915334\n","[9000]\ttraining's auc: 0.99985\tvalid_1's auc: 0.915241\n","[10000]\ttraining's auc: 0.999938\tvalid_1's auc: 0.915218\n","[11000]\ttraining's auc: 0.999977\tvalid_1's auc: 0.915167\n","[12000]\ttraining's auc: 0.999993\tvalid_1's auc: 0.915102\n","Early stopping, best iteration is:\n","[7849]\ttraining's auc: 0.999627\tvalid_1's auc: 0.915368\n","\n","Fold 4 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.971372\tvalid_1's auc: 0.88322\n","[2000]\ttraining's auc: 0.986883\tvalid_1's auc: 0.905544\n","[3000]\ttraining's auc: 0.992047\tvalid_1's auc: 0.913725\n","[4000]\ttraining's auc: 0.99517\tvalid_1's auc: 0.917241\n","[5000]\ttraining's auc: 0.997309\tvalid_1's auc: 0.918436\n","[6000]\ttraining's auc: 0.998584\tvalid_1's auc: 0.918654\n","[7000]\ttraining's auc: 0.999284\tvalid_1's auc: 0.9188\n","[8000]\ttraining's auc: 0.99966\tvalid_1's auc: 0.918755\n","[9000]\ttraining's auc: 0.999851\tvalid_1's auc: 0.918644\n","[10000]\ttraining's auc: 0.999942\tvalid_1's auc: 0.918584\n","[11000]\ttraining's auc: 0.99998\tvalid_1's auc: 0.918508\n","[12000]\ttraining's auc: 0.999995\tvalid_1's auc: 0.918544\n","Early stopping, best iteration is:\n","[7439]\ttraining's auc: 0.999481\tvalid_1's auc: 0.918825\n","\n","Fold 5 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.971647\tvalid_1's auc: 0.886245\n","[2000]\ttraining's auc: 0.986532\tvalid_1's auc: 0.909132\n","[3000]\ttraining's auc: 0.991803\tvalid_1's auc: 0.917841\n","[4000]\ttraining's auc: 0.995058\tvalid_1's auc: 0.921572\n","[5000]\ttraining's auc: 0.997258\tvalid_1's auc: 0.922852\n","[6000]\ttraining's auc: 0.998552\tvalid_1's auc: 0.923194\n","[7000]\ttraining's auc: 0.999268\tvalid_1's auc: 0.923348\n","[8000]\ttraining's auc: 0.999651\tvalid_1's auc: 0.923409\n","[9000]\ttraining's auc: 0.999845\tvalid_1's auc: 0.923382\n","[10000]\ttraining's auc: 0.999936\tvalid_1's auc: 0.923374\n","[11000]\ttraining's auc: 0.999977\tvalid_1's auc: 0.923327\n","[12000]\ttraining's auc: 0.999993\tvalid_1's auc: 0.923311\n","[13000]\ttraining's auc: 0.999998\tvalid_1's auc: 0.923316\n","Early stopping, best iteration is:\n","[8090]\ttraining's auc: 0.999675\tvalid_1's auc: 0.923453\n"]}],"source":["# Parameter 3\n","\n","for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param3, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N\n","\n","predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n","\n","sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_parameter3.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GVQ8znJrz9dE"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold 1 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.95899\tvalid_1's auc: 0.871865\n","[2000]\ttraining's auc: 0.977545\tvalid_1's auc: 0.899313\n","[3000]\ttraining's auc: 0.984191\tvalid_1's auc: 0.91081\n","[4000]\ttraining's auc: 0.987338\tvalid_1's auc: 0.916571\n","[5000]\ttraining's auc: 0.989273\tvalid_1's auc: 0.919781\n","[6000]\ttraining's auc: 0.990762\tvalid_1's auc: 0.921121\n","[7000]\ttraining's auc: 0.992066\tvalid_1's auc: 0.922018\n","[8000]\ttraining's auc: 0.993247\tvalid_1's auc: 0.922464\n","[9000]\ttraining's auc: 0.994306\tvalid_1's auc: 0.922538\n","[10000]\ttraining's auc: 0.99523\tvalid_1's auc: 0.922678\n","[11000]\ttraining's auc: 0.996052\tvalid_1's auc: 0.922595\n","[12000]\ttraining's auc: 0.996759\tvalid_1's auc: 0.922524\n","[13000]\ttraining's auc: 0.997374\tvalid_1's auc: 0.922499\n","[14000]\ttraining's auc: 0.997882\tvalid_1's auc: 0.922363\n","[15000]\ttraining's auc: 0.998315\tvalid_1's auc: 0.922349\n","Early stopping, best iteration is:\n","[10171]\ttraining's auc: 0.995381\tvalid_1's auc: 0.922726\n","\n","Fold 2 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.958254\tvalid_1's auc: 0.875992\n","[2000]\ttraining's auc: 0.976819\tvalid_1's auc: 0.900702\n","[3000]\ttraining's auc: 0.983786\tvalid_1's auc: 0.911603\n","[4000]\ttraining's auc: 0.987205\tvalid_1's auc: 0.917219\n","[5000]\ttraining's auc: 0.989166\tvalid_1's auc: 0.920086\n","[6000]\ttraining's auc: 0.990652\tvalid_1's auc: 0.921526\n","[7000]\ttraining's auc: 0.991939\tvalid_1's auc: 0.922254\n","[8000]\ttraining's auc: 0.993122\tvalid_1's auc: 0.922464\n","[9000]\ttraining's auc: 0.994186\tvalid_1's auc: 0.922782\n","[10000]\ttraining's auc: 0.995122\tvalid_1's auc: 0.922914\n","[11000]\ttraining's auc: 0.995945\tvalid_1's auc: 0.923011\n","[12000]\ttraining's auc: 0.996677\tvalid_1's auc: 0.92302\n","[13000]\ttraining's auc: 0.997308\tvalid_1's auc: 0.922951\n","[14000]\ttraining's auc: 0.997835\tvalid_1's auc: 0.922904\n","[15000]\ttraining's auc: 0.998281\tvalid_1's auc: 0.922823\n","[16000]\ttraining's auc: 0.998641\tvalid_1's auc: 0.922699\n","Early stopping, best iteration is:\n","[11225]\ttraining's auc: 0.996121\tvalid_1's auc: 0.923076\n","\n","Fold 3 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.959337\tvalid_1's auc: 0.868018\n","[2000]\ttraining's auc: 0.97783\tvalid_1's auc: 0.893499\n","[3000]\ttraining's auc: 0.98444\tvalid_1's auc: 0.904942\n","[4000]\ttraining's auc: 0.9876\tvalid_1's auc: 0.911173\n","[5000]\ttraining's auc: 0.989466\tvalid_1's auc: 0.914573\n","[6000]\ttraining's auc: 0.990889\tvalid_1's auc: 0.916512\n","[7000]\ttraining's auc: 0.992167\tvalid_1's auc: 0.917341\n","[8000]\ttraining's auc: 0.993328\tvalid_1's auc: 0.917829\n","[9000]\ttraining's auc: 0.99436\tvalid_1's auc: 0.918113\n","[10000]\ttraining's auc: 0.995293\tvalid_1's auc: 0.918107\n","[11000]\ttraining's auc: 0.996084\tvalid_1's auc: 0.918147\n","[12000]\ttraining's auc: 0.996786\tvalid_1's auc: 0.918318\n","[13000]\ttraining's auc: 0.997378\tvalid_1's auc: 0.918283\n","[14000]\ttraining's auc: 0.997891\tvalid_1's auc: 0.918201\n","[15000]\ttraining's auc: 0.998309\tvalid_1's auc: 0.918188\n","[16000]\ttraining's auc: 0.998662\tvalid_1's auc: 0.918101\n","[17000]\ttraining's auc: 0.998953\tvalid_1's auc: 0.918066\n","Early stopping, best iteration is:\n","[12349]\ttraining's auc: 0.997002\tvalid_1's auc: 0.918361\n","\n","Fold 4 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.958905\tvalid_1's auc: 0.874161\n","[2000]\ttraining's auc: 0.977706\tvalid_1's auc: 0.89943\n","[3000]\ttraining's auc: 0.984097\tvalid_1's auc: 0.910346\n","[4000]\ttraining's auc: 0.987271\tvalid_1's auc: 0.915997\n","[5000]\ttraining's auc: 0.989239\tvalid_1's auc: 0.919046\n","[6000]\ttraining's auc: 0.990722\tvalid_1's auc: 0.920543\n","[7000]\ttraining's auc: 0.992017\tvalid_1's auc: 0.921168\n","[8000]\ttraining's auc: 0.993199\tvalid_1's auc: 0.921501\n","[9000]\ttraining's auc: 0.994256\tvalid_1's auc: 0.921571\n","[10000]\ttraining's auc: 0.995182\tvalid_1's auc: 0.921616\n","[11000]\ttraining's auc: 0.995991\tvalid_1's auc: 0.921539\n","[12000]\ttraining's auc: 0.996696\tvalid_1's auc: 0.92162\n","[13000]\ttraining's auc: 0.997301\tvalid_1's auc: 0.921514\n","[14000]\ttraining's auc: 0.997827\tvalid_1's auc: 0.9215\n","[15000]\ttraining's auc: 0.998267\tvalid_1's auc: 0.921393\n","[16000]\ttraining's auc: 0.998633\tvalid_1's auc: 0.921284\n","[17000]\ttraining's auc: 0.998933\tvalid_1's auc: 0.921301\n","Early stopping, best iteration is:\n","[12321]\ttraining's auc: 0.996902\tvalid_1's auc: 0.921655\n","\n","Fold 5 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.959007\tvalid_1's auc: 0.877652\n","[2000]\ttraining's auc: 0.977171\tvalid_1's auc: 0.902412\n","[3000]\ttraining's auc: 0.983893\tvalid_1's auc: 0.913428\n","[4000]\ttraining's auc: 0.987025\tvalid_1's auc: 0.919503\n","[5000]\ttraining's auc: 0.989053\tvalid_1's auc: 0.922607\n","[6000]\ttraining's auc: 0.990545\tvalid_1's auc: 0.924218\n","[7000]\ttraining's auc: 0.99188\tvalid_1's auc: 0.924757\n","[8000]\ttraining's auc: 0.993065\tvalid_1's auc: 0.924958\n","[9000]\ttraining's auc: 0.994141\tvalid_1's auc: 0.92519\n","[10000]\ttraining's auc: 0.995081\tvalid_1's auc: 0.925251\n","[11000]\ttraining's auc: 0.995897\tvalid_1's auc: 0.925286\n","[12000]\ttraining's auc: 0.996634\tvalid_1's auc: 0.925228\n","[13000]\ttraining's auc: 0.997254\tvalid_1's auc: 0.925124\n","[14000]\ttraining's auc: 0.99779\tvalid_1's auc: 0.925017\n","[15000]\ttraining's auc: 0.998249\tvalid_1's auc: 0.924916\n","[16000]\ttraining's auc: 0.998624\tvalid_1's auc: 0.924882\n","Early stopping, best iteration is:\n","[11278]\ttraining's auc: 0.996107\tvalid_1's auc: 0.925328\n"]}],"source":["# Parameter 4\n","\n","for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param4, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N\n","\n","predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n","\n","sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_parameter4.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rEzlLnwH4oDj"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Fold 1 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.957508\tvalid_1's auc: 0.871449\n","[2000]\ttraining's auc: 0.976957\tvalid_1's auc: 0.898887\n","[3000]\ttraining's auc: 0.983754\tvalid_1's auc: 0.910567\n","[4000]\ttraining's auc: 0.987115\tvalid_1's auc: 0.916465\n","[5000]\ttraining's auc: 0.989097\tvalid_1's auc: 0.919707\n","[6000]\ttraining's auc: 0.990635\tvalid_1's auc: 0.921197\n","[7000]\ttraining's auc: 0.991945\tvalid_1's auc: 0.921957\n","[8000]\ttraining's auc: 0.99315\tvalid_1's auc: 0.922445\n","[9000]\ttraining's auc: 0.99423\tvalid_1's auc: 0.922485\n","[10000]\ttraining's auc: 0.995162\tvalid_1's auc: 0.922614\n","[11000]\ttraining's auc: 0.995988\tvalid_1's auc: 0.922537\n","[12000]\ttraining's auc: 0.996702\tvalid_1's auc: 0.922593\n","[13000]\ttraining's auc: 0.997324\tvalid_1's auc: 0.922589\n","[14000]\ttraining's auc: 0.997844\tvalid_1's auc: 0.922512\n","[15000]\ttraining's auc: 0.998282\tvalid_1's auc: 0.922396\n","Early stopping, best iteration is:\n","[10047]\ttraining's auc: 0.995201\tvalid_1's auc: 0.922641\n","\n","Fold 2 - N 1\n","Shape of X_train after augment: (336079, 925)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.957564\tvalid_1's auc: 0.876386\n","[2000]\ttraining's auc: 0.976915\tvalid_1's auc: 0.900875\n","[3000]\ttraining's auc: 0.983849\tvalid_1's auc: 0.911829\n","[4000]\ttraining's auc: 0.987225\tvalid_1's auc: 0.917407\n","[5000]\ttraining's auc: 0.989184\tvalid_1's auc: 0.920338\n","[6000]\ttraining's auc: 0.990684\tvalid_1's auc: 0.921806\n","[7000]\ttraining's auc: 0.99198\tvalid_1's auc: 0.922419\n","[8000]\ttraining's auc: 0.993141\tvalid_1's auc: 0.922751\n","[9000]\ttraining's auc: 0.994194\tvalid_1's auc: 0.922892\n","[10000]\ttraining's auc: 0.995132\tvalid_1's auc: 0.922997\n","[11000]\ttraining's auc: 0.995962\tvalid_1's auc: 0.923107\n","[12000]\ttraining's auc: 0.996688\tvalid_1's auc: 0.923069\n","[13000]\ttraining's auc: 0.997311\tvalid_1's auc: 0.922985\n","[14000]\ttraining's auc: 0.997838\tvalid_1's auc: 0.92305\n","[15000]\ttraining's auc: 0.998281\tvalid_1's auc: 0.923009\n","[16000]\ttraining's auc: 0.998646\tvalid_1's auc: 0.922842\n","Early stopping, best iteration is:\n","[11143]\ttraining's auc: 0.996077\tvalid_1's auc: 0.923147\n","\n","Fold 3 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.958911\tvalid_1's auc: 0.868034\n","[2000]\ttraining's auc: 0.977852\tvalid_1's auc: 0.89337\n","[3000]\ttraining's auc: 0.984263\tvalid_1's auc: 0.904733\n","[4000]\ttraining's auc: 0.987414\tvalid_1's auc: 0.910881\n","[5000]\ttraining's auc: 0.989331\tvalid_1's auc: 0.914358\n","[6000]\ttraining's auc: 0.990795\tvalid_1's auc: 0.916414\n","[7000]\ttraining's auc: 0.992086\tvalid_1's auc: 0.917232\n","[8000]\ttraining's auc: 0.993257\tvalid_1's auc: 0.917727\n","[9000]\ttraining's auc: 0.994293\tvalid_1's auc: 0.918007\n","[10000]\ttraining's auc: 0.995229\tvalid_1's auc: 0.918144\n","[11000]\ttraining's auc: 0.996028\tvalid_1's auc: 0.9183\n","[12000]\ttraining's auc: 0.996735\tvalid_1's auc: 0.918377\n","[13000]\ttraining's auc: 0.997338\tvalid_1's auc: 0.918263\n","[14000]\ttraining's auc: 0.99785\tvalid_1's auc: 0.918094\n","[15000]\ttraining's auc: 0.998274\tvalid_1's auc: 0.918117\n","[16000]\ttraining's auc: 0.998631\tvalid_1's auc: 0.918061\n","[17000]\ttraining's auc: 0.998926\tvalid_1's auc: 0.917969\n","Early stopping, best iteration is:\n","[12355]\ttraining's auc: 0.996959\tvalid_1's auc: 0.918425\n","\n","Fold 4 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.957811\tvalid_1's auc: 0.874851\n","[2000]\ttraining's auc: 0.977787\tvalid_1's auc: 0.900123\n","[3000]\ttraining's auc: 0.984315\tvalid_1's auc: 0.910301\n","[4000]\ttraining's auc: 0.987388\tvalid_1's auc: 0.915868\n","[5000]\ttraining's auc: 0.98931\tvalid_1's auc: 0.918753\n","[6000]\ttraining's auc: 0.990793\tvalid_1's auc: 0.920356\n","[7000]\ttraining's auc: 0.992077\tvalid_1's auc: 0.921006\n","[8000]\ttraining's auc: 0.993242\tvalid_1's auc: 0.921295\n","[9000]\ttraining's auc: 0.994288\tvalid_1's auc: 0.921389\n","[10000]\ttraining's auc: 0.995206\tvalid_1's auc: 0.921452\n","[11000]\ttraining's auc: 0.996016\tvalid_1's auc: 0.921469\n","[12000]\ttraining's auc: 0.996721\tvalid_1's auc: 0.921408\n","[13000]\ttraining's auc: 0.99734\tvalid_1's auc: 0.921246\n","[14000]\ttraining's auc: 0.997861\tvalid_1's auc: 0.921214\n","[15000]\ttraining's auc: 0.998293\tvalid_1's auc: 0.921107\n","Early stopping, best iteration is:\n","[10862]\ttraining's auc: 0.995905\tvalid_1's auc: 0.921516\n","\n","Fold 5 - N 1\n","Shape of X_train after augment: (336078, 925)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.959122\tvalid_1's auc: 0.877653\n","[2000]\ttraining's auc: 0.97749\tvalid_1's auc: 0.902688\n","[3000]\ttraining's auc: 0.984023\tvalid_1's auc: 0.913657\n","[4000]\ttraining's auc: 0.987123\tvalid_1's auc: 0.919543\n","[5000]\ttraining's auc: 0.989132\tvalid_1's auc: 0.922611\n","[6000]\ttraining's auc: 0.990623\tvalid_1's auc: 0.924018\n","[7000]\ttraining's auc: 0.99194\tvalid_1's auc: 0.924552\n","[8000]\ttraining's auc: 0.993115\tvalid_1's auc: 0.924908\n","[9000]\ttraining's auc: 0.994179\tvalid_1's auc: 0.925079\n","[10000]\ttraining's auc: 0.995121\tvalid_1's auc: 0.925259\n","[11000]\ttraining's auc: 0.995941\tvalid_1's auc: 0.925272\n","[12000]\ttraining's auc: 0.996668\tvalid_1's auc: 0.925314\n","[13000]\ttraining's auc: 0.99728\tvalid_1's auc: 0.925227\n","[14000]\ttraining's auc: 0.997805\tvalid_1's auc: 0.925127\n","[15000]\ttraining's auc: 0.998257\tvalid_1's auc: 0.925093\n","[16000]\ttraining's auc: 0.998633\tvalid_1's auc: 0.92497\n","Early stopping, best iteration is:\n","[11312]\ttraining's auc: 0.996174\tvalid_1's auc: 0.925371\n"]}],"source":["# Parameter 5\n","\n","for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param4, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N\n","\n","predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n","\n","sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_parameter5.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zicDu76UJjnL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyN6nh01D5A0gKc+yPR9vjab","machine_shape":"hm","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}