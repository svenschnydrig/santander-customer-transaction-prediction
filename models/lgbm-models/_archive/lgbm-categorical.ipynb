{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5463,"status":"ok","timestamp":1671574880138,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"},"user_tz":-60},"id":"mkRE647nj_iM","outputId":"8916b523-0fb4-4e8c-edc8-edf39cc82819"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## Importing libraries\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import roc_auc_score\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n","from sklearn.cluster import KMeans\n","import lightgbm as lgb\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","SEED = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aT_wknkikKOg"},"outputs":[],"source":["## Importing data\n","\n","df_train = pd.read_csv(\"/content/drive/MyDrive/Data Science Project - Team D/data/fe1-categorical/train_fe1_categorical.csv\")\n","df_test = pd.read_csv(\"/content/drive/MyDrive/Data Science Project - Team D/data/fe1-categorical/test_fe1_categorical.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9dq23A0vkGxo"},"outputs":[],"source":["## Oversampling \n","\n","def oversampling(x, y, t=2):\n","    \n","    xs, xn = [], []\n","    \n","    for i in range(t // 2):\n","        mask = y == 0\n","        x1 = x[mask].copy()\n","        ids = np.arange(x1.shape[0])\n","        featnum = x1.shape[1] // 200 - 1\n","\n","        for c in range(200):\n","            np.random.shuffle(ids)\n","            x1[:, [c] + [200 + featnum * c + idc for idc in range(featnum)]] = x1[ids][:, [c] + [200 + featnum * c + idc for idc in range(featnum)]]\n","        xn.append(x1)\n","    \n","    for i in range(t):\n","        mask = y > 0\n","        x1 = x[mask].copy()\n","        ids = np.arange(x1.shape[0])\n","        featnum = x1.shape[1] // 200 - 1\n","        \n","        for c in range(200):\n","            np.random.shuffle(ids)\n","            x1[:, [c] + [200 + featnum * c + idc for idc in range(1)]] = x1[ids][:, [c] + [200 + featnum * c + idc for idc in range(1)]]\n","        xs.append(x1)\n","\n","    xs = np.vstack(xs)\n","    xn = np.vstack(xn)\n","    ys = np.ones(xs.shape[0])\n","    yn = np.zeros(xn.shape[0])\n","    x = np.vstack([x, xs, xn])\n","    y = np.concatenate([y, ys, yn])\n","    \n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIGjpIRWo0-B"},"outputs":[],"source":["gbdt_param1 = {\n","    # Core Parameters\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'learning_rate': 0.01,\n","    'num_leaves': 15,\n","    'tree_learner': 'serial',\n","    'num_threads': 8,\n","    'seed': SEED,\n","    \n","    # Learning Control Parameters\n","    'max_depth': -1,\n","    'min_data_in_leaf': 50,\n","    'min_sum_hessian_in_leaf': 10,  \n","    'bagging_fraction': 0.6,\n","    'bagging_freq': 5,\n","    'feature_fraction': 0.05,\n","    'lambda_l1': 1.,\n","    'bagging_seed': SEED,\n","    \n","    # Others\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gg0fHChulnI1"},"outputs":[],"source":["predictors = df_train.columns.tolist()[2:]\n","X_test = df_test[predictors]\n","\n","n_splits = 5\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n","\n","predictions = df_test[['ID_code']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VNCpctOlpZ0","outputId":"5032eedf-f748-4f3b-99dd-f4a2cee77e5a","executionInfo":{"status":"ok","timestamp":1671572032214,"user_tz":-60,"elapsed":3864872,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Fold 1 - N 1\n","Shape of X_train after augment: (336079, 800)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.931514\tvalid_1's auc: 0.889169\n","[2000]\ttraining's auc: 0.945811\tvalid_1's auc: 0.901474\n","[3000]\ttraining's auc: 0.954863\tvalid_1's auc: 0.910187\n","[4000]\ttraining's auc: 0.960911\tvalid_1's auc: 0.915059\n","[5000]\ttraining's auc: 0.965772\tvalid_1's auc: 0.918287\n","[6000]\ttraining's auc: 0.969375\tvalid_1's auc: 0.920287\n","[7000]\ttraining's auc: 0.972249\tvalid_1's auc: 0.921574\n","[8000]\ttraining's auc: 0.974713\tvalid_1's auc: 0.922422\n","[9000]\ttraining's auc: 0.976661\tvalid_1's auc: 0.922904\n","[10000]\ttraining's auc: 0.978544\tvalid_1's auc: 0.923146\n","[11000]\ttraining's auc: 0.980247\tvalid_1's auc: 0.923334\n","[12000]\ttraining's auc: 0.981888\tvalid_1's auc: 0.923453\n","[13000]\ttraining's auc: 0.983311\tvalid_1's auc: 0.923518\n","[14000]\ttraining's auc: 0.98461\tvalid_1's auc: 0.923486\n","[15000]\ttraining's auc: 0.985849\tvalid_1's auc: 0.923491\n","[16000]\ttraining's auc: 0.986957\tvalid_1's auc: 0.923528\n","[17000]\ttraining's auc: 0.987983\tvalid_1's auc: 0.923509\n","[18000]\ttraining's auc: 0.989\tvalid_1's auc: 0.923498\n","[19000]\ttraining's auc: 0.989902\tvalid_1's auc: 0.923446\n","[20000]\ttraining's auc: 0.990759\tvalid_1's auc: 0.923426\n","[21000]\ttraining's auc: 0.991604\tvalid_1's auc: 0.923453\n","Early stopping, best iteration is:\n","[16306]\ttraining's auc: 0.987281\tvalid_1's auc: 0.923549\n","\n","Fold 2 - N 1\n","Shape of X_train after augment: (336079, 800)\n","Shape of y_train after augment: (336079,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.931092\tvalid_1's auc: 0.892119\n","[2000]\ttraining's auc: 0.944895\tvalid_1's auc: 0.903845\n","[3000]\ttraining's auc: 0.954133\tvalid_1's auc: 0.911775\n","[4000]\ttraining's auc: 0.959775\tvalid_1's auc: 0.916092\n","[5000]\ttraining's auc: 0.965067\tvalid_1's auc: 0.918925\n","[6000]\ttraining's auc: 0.968654\tvalid_1's auc: 0.920677\n","[7000]\ttraining's auc: 0.97129\tvalid_1's auc: 0.921692\n","[8000]\ttraining's auc: 0.973682\tvalid_1's auc: 0.922412\n","[9000]\ttraining's auc: 0.976016\tvalid_1's auc: 0.922795\n","[10000]\ttraining's auc: 0.977778\tvalid_1's auc: 0.92302\n","[11000]\ttraining's auc: 0.979549\tvalid_1's auc: 0.923218\n","[12000]\ttraining's auc: 0.980941\tvalid_1's auc: 0.923241\n","[13000]\ttraining's auc: 0.982341\tvalid_1's auc: 0.923271\n","[14000]\ttraining's auc: 0.983769\tvalid_1's auc: 0.923301\n","[15000]\ttraining's auc: 0.985185\tvalid_1's auc: 0.923313\n","[16000]\ttraining's auc: 0.986369\tvalid_1's auc: 0.92329\n","[17000]\ttraining's auc: 0.987526\tvalid_1's auc: 0.923268\n","[18000]\ttraining's auc: 0.98858\tvalid_1's auc: 0.923164\n","[19000]\ttraining's auc: 0.989545\tvalid_1's auc: 0.923115\n","Early stopping, best iteration is:\n","[14817]\ttraining's auc: 0.984927\tvalid_1's auc: 0.923337\n","\n","Fold 3 - N 1\n","Shape of X_train after augment: (336078, 800)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.932127\tvalid_1's auc: 0.884698\n","[2000]\ttraining's auc: 0.945542\tvalid_1's auc: 0.89684\n","[3000]\ttraining's auc: 0.955217\tvalid_1's auc: 0.904848\n","[4000]\ttraining's auc: 0.961186\tvalid_1's auc: 0.909827\n","[5000]\ttraining's auc: 0.96565\tvalid_1's auc: 0.91296\n","[6000]\ttraining's auc: 0.969217\tvalid_1's auc: 0.914955\n","[7000]\ttraining's auc: 0.972088\tvalid_1's auc: 0.916388\n","[8000]\ttraining's auc: 0.974547\tvalid_1's auc: 0.917326\n","[9000]\ttraining's auc: 0.976502\tvalid_1's auc: 0.917945\n","[10000]\ttraining's auc: 0.978431\tvalid_1's auc: 0.918307\n","[11000]\ttraining's auc: 0.980099\tvalid_1's auc: 0.918574\n","[12000]\ttraining's auc: 0.981594\tvalid_1's auc: 0.918725\n","[13000]\ttraining's auc: 0.983017\tvalid_1's auc: 0.918856\n","[14000]\ttraining's auc: 0.984416\tvalid_1's auc: 0.918923\n","[15000]\ttraining's auc: 0.985691\tvalid_1's auc: 0.918942\n","[16000]\ttraining's auc: 0.986861\tvalid_1's auc: 0.918961\n","[17000]\ttraining's auc: 0.987883\tvalid_1's auc: 0.918971\n","[18000]\ttraining's auc: 0.988862\tvalid_1's auc: 0.918934\n","[19000]\ttraining's auc: 0.989854\tvalid_1's auc: 0.918894\n","[20000]\ttraining's auc: 0.990784\tvalid_1's auc: 0.918924\n","[21000]\ttraining's auc: 0.991663\tvalid_1's auc: 0.918872\n","Early stopping, best iteration is:\n","[16833]\ttraining's auc: 0.987723\tvalid_1's auc: 0.919008\n","\n","Fold 4 - N 1\n","Shape of X_train after augment: (336078, 800)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.931703\tvalid_1's auc: 0.890653\n","[2000]\ttraining's auc: 0.945595\tvalid_1's auc: 0.902098\n","[3000]\ttraining's auc: 0.955143\tvalid_1's auc: 0.909953\n","[4000]\ttraining's auc: 0.960646\tvalid_1's auc: 0.914623\n","[5000]\ttraining's auc: 0.965606\tvalid_1's auc: 0.91748\n","[6000]\ttraining's auc: 0.969246\tvalid_1's auc: 0.919223\n","[7000]\ttraining's auc: 0.972218\tvalid_1's auc: 0.920356\n","[8000]\ttraining's auc: 0.974555\tvalid_1's auc: 0.921105\n","[9000]\ttraining's auc: 0.976773\tvalid_1's auc: 0.921623\n","[10000]\ttraining's auc: 0.978552\tvalid_1's auc: 0.921966\n","[11000]\ttraining's auc: 0.980318\tvalid_1's auc: 0.922143\n","[12000]\ttraining's auc: 0.981755\tvalid_1's auc: 0.922252\n","[13000]\ttraining's auc: 0.983019\tvalid_1's auc: 0.922263\n","[14000]\ttraining's auc: 0.984395\tvalid_1's auc: 0.922273\n","[15000]\ttraining's auc: 0.985737\tvalid_1's auc: 0.922244\n","[16000]\ttraining's auc: 0.986899\tvalid_1's auc: 0.922254\n","[17000]\ttraining's auc: 0.987976\tvalid_1's auc: 0.922202\n","[18000]\ttraining's auc: 0.98901\tvalid_1's auc: 0.922101\n","[19000]\ttraining's auc: 0.989932\tvalid_1's auc: 0.922055\n","Early stopping, best iteration is:\n","[14160]\ttraining's auc: 0.984569\tvalid_1's auc: 0.922283\n","\n","Fold 5 - N 1\n","Shape of X_train after augment: (336078, 800)\n","Shape of y_train after augment: (336078,)\n","Training until validation scores don't improve for 5000 rounds.\n","[1000]\ttraining's auc: 0.930886\tvalid_1's auc: 0.892684\n","[2000]\ttraining's auc: 0.944616\tvalid_1's auc: 0.904838\n","[3000]\ttraining's auc: 0.953828\tvalid_1's auc: 0.913029\n","[4000]\ttraining's auc: 0.959871\tvalid_1's auc: 0.917883\n","[5000]\ttraining's auc: 0.964583\tvalid_1's auc: 0.920933\n","[6000]\ttraining's auc: 0.968226\tvalid_1's auc: 0.922689\n","[7000]\ttraining's auc: 0.970944\tvalid_1's auc: 0.923906\n","[8000]\ttraining's auc: 0.973376\tvalid_1's auc: 0.924595\n","[9000]\ttraining's auc: 0.975723\tvalid_1's auc: 0.925033\n","[10000]\ttraining's auc: 0.977851\tvalid_1's auc: 0.925378\n","[11000]\ttraining's auc: 0.979554\tvalid_1's auc: 0.925573\n","[12000]\ttraining's auc: 0.981217\tvalid_1's auc: 0.925686\n","[13000]\ttraining's auc: 0.982687\tvalid_1's auc: 0.92575\n","[14000]\ttraining's auc: 0.984145\tvalid_1's auc: 0.925782\n","[15000]\ttraining's auc: 0.985392\tvalid_1's auc: 0.925775\n","[16000]\ttraining's auc: 0.98659\tvalid_1's auc: 0.925808\n","[17000]\ttraining's auc: 0.98771\tvalid_1's auc: 0.925803\n","[18000]\ttraining's auc: 0.988721\tvalid_1's auc: 0.925785\n","[19000]\ttraining's auc: 0.989765\tvalid_1's auc: 0.925764\n","[20000]\ttraining's auc: 0.990677\tvalid_1's auc: 0.925692\n","Early stopping, best iteration is:\n","[15605]\ttraining's auc: 0.986152\tvalid_1's auc: 0.925833\n"]}],"source":["for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param1, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1bNjflUlrWT"},"outputs":[],"source":["predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDr_jaBeABw1"},"outputs":[],"source":["sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_lgbm_fe1_categorical.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVPPO6UyAQoH","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"error","timestamp":1671574375681,"user_tz":-60,"elapsed":213,"user":{"displayName":"Sven Schnydrig","userId":"07537939478620197257"}},"outputId":"7770e97e-74ea-42e8-e18f-ce16ebaf6723"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-cfc58fbc987d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Importing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Data Science Project - Team D/data/fe2-categorical/train_fe2_categorical.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Data Science Project - Team D/data/fe2-categorical/test_fe2_categorical.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Data Science Project - Team D/data/fe2-categorical/train_fe2_categorical.csv'"]}],"source":["## Importing data\n","\n","df_train = pd.read_csv(\"/content/drive/MyDrive/Data Science Project - Team D/data/fe2-categorical/train_fe2_categorical.csv\")\n","df_test = pd.read_csv(\"/content/drive/MyDrive/Data Science Project - Team D/data/fe2-categorical/test_fe2_categorical.csv\")"]},{"cell_type":"code","source":["## Oversampling \n","\n","def oversampling(x, y, t=2):\n","    \n","    xs, xn = [], []\n","    \n","    for i in range(t // 2):\n","        mask = y == 0\n","        x1 = x[mask].copy()\n","        ids = np.arange(x1.shape[0])\n","        featnum = x1.shape[1] // 200 - 1\n","\n","        for c in range(200):\n","            np.random.shuffle(ids)\n","            x1[:, [c] + [200 + featnum * c + idc for idc in range(featnum)]] = x1[ids][:, [c] + [200 + featnum * c + idc for idc in range(featnum)]]\n","        xn.append(x1)\n","    \n","    for i in range(t):\n","        mask = y > 0\n","        x1 = x[mask].copy()\n","        ids = np.arange(x1.shape[0])\n","        featnum = x1.shape[1] // 200 - 1\n","        \n","        for c in range(200):\n","            np.random.shuffle(ids)\n","            x1[:, [c] + [200 + featnum * c + idc for idc in range(1)]] = x1[ids][:, [c] + [200 + featnum * c + idc for idc in range(1)]]\n","        xs.append(x1)\n","\n","    xs = np.vstack(xs)\n","    xn = np.vstack(xn)\n","    ys = np.ones(xs.shape[0])\n","    yn = np.zeros(xn.shape[0])\n","    x = np.vstack([x, xs, xn])\n","    y = np.concatenate([y, ys, yn])\n","    \n","    return x, y"],"metadata":{"id":"bgdso0JCl-i_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbdt_param1 = {\n","    # Core Parameters\n","    'objective': 'binary',\n","    'boosting': 'gbdt',\n","    'learning_rate': 0.01,\n","    'num_leaves': 15,\n","    'tree_learner': 'serial',\n","    'num_threads': 8,\n","    'seed': SEED,\n","    \n","    # Learning Control Parameters\n","    'max_depth': -1,\n","    'min_data_in_leaf': 50,\n","    'min_sum_hessian_in_leaf': 10,  \n","    'bagging_fraction': 0.6,\n","    'bagging_freq': 5,\n","    'feature_fraction': 0.05,\n","    'lambda_l1': 1.,\n","    'bagging_seed': SEED,\n","    \n","    # Others\n","    'verbosity ': 1,\n","    'boost_from_average': False,\n","    'metric': 'auc',\n","}"],"metadata":{"id":"8NIVMFwKmAMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictors = df_train.columns.tolist()[2:]\n","X_test = df_test[predictors]\n","\n","n_splits = 5\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n","\n","predictions = df_test[['ID_code']]"],"metadata":{"id":"XGrbeCJzmEFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fold, (train_ind, val_ind) in enumerate(skf.split(df_train, df_train.target.values)):\n","    \n","    X_train, y_train = df_train.iloc[train_ind][predictors], df_train.iloc[train_ind]['target']\n","    X_valid, y_valid = df_train.iloc[val_ind][predictors], df_train.iloc[val_ind]['target']\n","\n","    N = 1\n","    p_valid, yp = 0, 0\n","        \n","    for i in range(N):\n","        print('\\nFold {} - N {}'.format(fold + 1, i + 1))\n","        \n","        X_t, y_t = oversampling(X_train.values, y_train.values)\n","        weights = np.array([0.8] * X_t.shape[0])\n","        weights[:X_train.shape[0]] = 1.0\n","        print('Shape of X_train after augment: {}\\nShape of y_train after augment: {}'.format(X_t.shape, y_t.shape))\n","        \n","        X_t = pd.DataFrame(X_t)\n","        X_t = X_t.add_prefix('var_')\n","    \n","        trn_data = lgb.Dataset(X_t, label=y_t, weight=weights)\n","        val_data = lgb.Dataset(X_valid, label=y_valid)\n","        evals_result = {}\n","        \n","        lgb_clf = lgb.train(gbdt_param1, trn_data, 100000, valid_sets=[trn_data, val_data], early_stopping_rounds=5000, verbose_eval=1000, evals_result=evals_result)\n","        p_valid += lgb_clf.predict(X_valid)\n","        yp += lgb_clf.predict(X_test)\n","        \n","\n","    predictions['fold{}'.format(fold + 1)] = yp / N"],"metadata":{"id":"hL5-LJHhmFns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\n","predictions.to_csv('predictions.csv', index=None)\n","sub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\n","sub_df[\"target\"] = predictions['target']\n"],"metadata":{"id":"ynuVfYPvmG0p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub_df.to_csv(\"/content/drive/MyDrive/Data Science Project - Team D/submission/submission_lgbm_fe2_categorical.csv\", index=False)"],"metadata":{"id":"QpC4DkDOmIaD"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyO8WBYg8qfWOIWqEw0N1Gru"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}